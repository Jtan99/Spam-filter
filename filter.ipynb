{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Ntlk:\", nltk.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('SMSSpamCollection', header = None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "classes = df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "text_messages = df[1]\n",
    "Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace money symbols with 'moneysymb'\n",
    "money_pattern = r'£|\\$'\n",
    "processed_text = text_messages.str.replace(money_pattern, 'moneysymb', regex=True)\n",
    "\n",
    "# replace email with 'emailaddr'\n",
    "email_pattern = r'([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+'\n",
    "processed_text = processed_text.str.replace(email_pattern, 'emailaddr', regex=True)\n",
    "\n",
    "# replace urls with 'webaddress'\n",
    "url_pattern = r'^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$'\n",
    "processed_text = processed_text.str.replace(url_pattern, 'webaddress', regex=True)\n",
    "\n",
    "# replace phone numbers with 'phonenumber'\n",
    "phone_pattern = r'(?:\\(\\d{3}\\)[- ]?\\d{3}[- ]?\\d{4}|0\\d{10})'\n",
    "processed_text = processed_text.str.replace(phone_pattern, 'phonenumber', regex=True)\n",
    "\n",
    "# repalce normal numbers with 'numberpat'\n",
    "number_pattern = r'\\d+(\\.\\d+)?'\n",
    "processed_text = processed_text.str.replace(number_pattern, 'numberpat', regex=True)\n",
    "\n",
    "# remove punctuation\n",
    "punctuations = r'[^\\w\\d\\s]'\n",
    "processed_text = processed_text.str.replace(punctuations, '', regex=True)\n",
    "\n",
    "# replace extra whitespaces with single whitespace\n",
    "extra_whitespace_pattern = r'\\s+|^\\s+|\\s+?$'\n",
    "processed_text = processed_text.str.replace(extra_whitespace_pattern, ' ', regex=True)\n",
    "\n",
    "# to lower case\n",
    "processed_text = processed_text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                              go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
       "1                                                                                                                                                                                             ok lar joking wif u oni\n",
       "2                                free entry in numberpat a wkly comp to win fa cup final tkts numberpatst may numberpat text fa to numberpat to receive entry questionstd txt ratetcs apply phonenumberovernumberpats\n",
       "3                                                                                                                                                                         u dun say so early hor u c already then say\n",
       "4                                                                                                                                                         nah i dont think he goes to usf he lives around here though\n",
       "5                                                   freemsg hey there darling its been numberpat weeks now and no word back id like some fun you up for it still tb ok xxx std chgs to send moneysymbnumberpat to rcv\n",
       "6                                                                                                                                         even my brother is not like to speak with me they treat me like aids patent\n",
       "7                                                  as per your request melle melle oru minnaminunginte nurungu vettam has been set as your callertune for all callers press numberpat to copy your friends callertune\n",
       "8                                  winner as a valued network customer you have been selected to receivea moneysymbnumberpat prize reward to claim call phonenumber claim code klnumberpat valid numberpat hours only\n",
       "9                                                     had your mobile numberpat months or more u r entitled to update to the latest colour mobiles with camera for free call the mobile update co free on phonenumber\n",
       "10                                                                                                            im gonna be home soon and i dont want to talk about this stuff anymore tonight k ive cried enough today\n",
       "11                        six chances to win cash from numberpat to numberpatnumberpat pounds txt cshnumberpat and send to numberpat cost numberpatpday numberpatdays numberpat tsandcs apply reply hl numberpat info\n",
       "12    urgent you have won a numberpat week free membership in our moneysymbnumberpatnumberpat prize jackpot txt the word claim to no numberpat tc wwwdbuknet lccltd pobox numberpatldnwnumberpatanumberpatrwnumberpat\n",
       "13                   ive been searching for the right words to thank you for this breather i promise i wont take your help for granted and will fulfil my promise you have been wonderful and a blessing at all times\n",
       "14                                                                                                                                                                                  i have a date on sunday with will\n",
       "15                                                                         xxxmobilemovieclub to use your credit click the wap link in the next txt message or click here httpwap xxxmobilemovieclubcomnqjkgighjjgcbl\n",
       "16                                                                                                                                                                                               oh kim watching here\n",
       "17                                                                                                                               eh u remember how numberpat spell his name yes i did he v naughty make until i v wet\n",
       "18                                                                                                                                                              fine if thats the way u feel thats the way its gota b\n",
       "19                         england v macedonia dont miss the goalsteam news txt ur national team to numberpat eg england to numberpat trywales scotland numberpattxtúnumberpat poboxoxnumberpatwnumberpatwq numberpat\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_text = processed_text.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                 go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n",
       "1                                                                                                                                                        ok lar joke wif u oni\n",
       "2           free entri numberpat wkli comp win fa cup final tkt numberpatst may numberpat text fa numberpat receiv entri questionstd txt ratetc appli phonenumberovernumberpat\n",
       "3                                                                                                                                          u dun say earli hor u c alreadi say\n",
       "4                                                                                                                                    nah dont think goe usf live around though\n",
       "                                                                                         ...                                                                                  \n",
       "5567    numberpatnd time tri numberpat contact u u moneysymbnumberpat pound prize numberpat claim easi call phonenumbernumberpat nownumberpat numberpatp per minut btnationalr\n",
       "5568                                                                                                                                                   ü b go esplanad fr home\n",
       "5569                                                                                                                                                   piti mood soani suggest\n",
       "5570                                                                                                      guy bitch act like id interest buy someth els next week gave us free\n",
       "5571                                                                                                                                                            rofl true name\n",
       "Name: 1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip suffixes, keeping only stem\n",
    "ps = nltk.PorterStemmer()\n",
    "processed_text = processed_text.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word in our processed text is a feature\n",
    "features = []\n",
    "for message in processed_text:\n",
    "  features += word_tokenize(message)\n",
    "features_freq = nltk.FreqDist(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words ['numberpat', 'u', 'call', 'im', 'go', 'get', 'ur', 'phonenumb', 'come', 'dont', 'ok', 'ltgt', 'free', 'know', 'moneysymbnumberpat', 'like', 'got', 'love', 'want', 'ill', 'day', 'time', 'good', 'text', 'send', 'need', 'one', 'txt', 'see', 'today', 'ü', 'think', 'home', 'take', 'lor', 'stop', 'repli', 'tell', 'sorri', 'still', 'r', 'back', 'mobil', 'make', 'n', 'phone', 'say', 'new', 'work', 'pleas', 'well', 'week', 'later', 'hi', 'da', 'ask', 'miss', 'cant', 'hope', 'meet', 'happi', 'night', 'tri', 'give', 'claim', 'wait', 'thing', 'oh', 'much', 'great', 'hey', 'pl', 'dear', 'wat', 'messag', 'number', 'na', 'friend', 'thank', 'that', 'way', 'prize', 'right', 'feel', 'msg', 'wan', 'even', 'let', 'pick', 'alreadi', 'tomorrow', 'said', 'ye', 'realli', 'yeah', 'min', 'e', 'amp', 'leav', 'care', 'co', 'didnt', 'babe', 'morn', 'win', 'c', 'life', 'last', 'sure', 'servic', 'ive', 'anyth', 'would', 'keep', 'cash', 'find', 'year', 'contact', 'buy', 'sleep', 'lol', 'tone', 'look', 'everi', 'k', 'use', 'nokia', 'start', 'smile', 'wish', 'also', 'watch', 'someth', 'show', 'sent', 'finish', 'end', 'award', 'b', 'urgent', 'place', 'gud', 'numberpatp', 'us', 'guy', 'custom', 'tonight', 'next', 'first', 'person', 'around', 'talk', 'someon', 'went', 'could', 'gon', 'soon', 'collect', 'chat', 'mani', 'per', 'help', 'late', 'plan', 'live', 'alway', 'nice', 'money', 'word', 'wont', 'ya', 'minut', 'dun', 'special', 'check', 'your', 'told', 'tc', 'name', 'v', 'mean', 'lot', 'hour', 'x', 'reach', 'peopl', 'guarante', 'shop', 'hello', 'girl', 'yet', 'happen', 'thk', 'done', 'may', 'thought', 'havent', 'haha', 'class', 'offer', 'play', 'fuck', 'receiv', 'bit', 'best', 'line', 'fine', 'lunch', 'eat', 'how', 'man', 'never', 'job', 'heart', 'stuff', 'car', 'mayb', 'draw', 'holiday', 'enjoy', 'month', 'yup', 'account', 'sm', 'cool', 'long', 'drive', 'guess', 'better', 'dat', 'readi', 'god', 'mind', 'numberpatst', 'chanc', 'pay', 'worri', 'problem', 'latest', 'cost', 'wonder', 'weekend', 'room', 'numberpatppm', 'luv', 'boy', 'bring', 'quit', 'lar', 'date', 'half', 'box', 'noth', 'hous', 'book', 'game', 'numberpatnumberpat', 'yo', 'anoth', 'big', 'voucher', 'world', 'select', 'camera', 'charg', 'sweet', 'real', 'birthday', 'landlin', 'stay', 'shit', 'kiss', 'put', 'speak', 'dinner', 'po', 'numberpatnumberpatnumberpat', 'join', 'sir', 'liao', 'ju', 'ever', 'id', 'xxx', 'rememb', 'question', 'what', 'might', 'actual', 'point', 'final', 'appli', 'earli', 'network', 'he', 'di', 'hear', 'hurt', 'chang', 'aight', 'two', 'probabl', 'pic', 'fun', 'rington', 'run', 'part', 'pa', 'bed', 'numberpatth', 'rate', 'answer', 'video', 'babi', 'den', 'princess', 'left', 'forgot', 'anyway', 'easi', 'walk', 'thanx', 'wake', 'made', 'dunno', 'orang', 'bad', 'code', 'there', 'numberpatnd', 'frnd', 'ah', 'littl', 'everyth', 'dad', 'enough', 'bu', 'pain', 'numberpathr', 'school', 'leh', 'face', 'bore', 'shall', 'she', 'mate', 'pound', 'doesnt', 'afternoon', 'dream', 'without', 'tv', 'xma', 'tmr', 'sound', 'g', 'lose', 'read', 'movi', 'sat', 'detail', 'gift', 'await', 'wif', 'credit', 'decid', 'sinc', 'came', 'wk', 'test', 'must', 'mail', 'sexi', 'post', 'town', 'entri', 'goe', 'though', 'set', 'uk', 'lesson', 'abt', 'okay', 'bt', 'smoke', 'abl', 'hav', 'import', 'true', 'offic', 'updat', 'mob', 'wen', 'price', 'juz', 'enter', 'order', 'bath', 'til', 'plz', 'poli', 'drink', 'away', 'plu', 'colour', 'moneysymbnumberpatnumberpat', 'till', 'hair', 'els', 'top', 'hand', 'music', 'weekli', 'wot', 'dude', 'attempt', 'de', 'drop', 'numberpatpmin', 'valid', 'alright', 'invit', 'saw', 'yesterday', 'doubl', 'trip', 'food', 'haf', 'ltdecimalgt', 'oso', 'head', 'beauti', 'lei', 'search', 'deliveri', 'close', 'busi', 'yr', 'open', 'si', 'hold', 'hot', 'friendship', 'either', 'sch', 'wife', 'onlin', 'brother', 'ard', 'mom', 'second', 'bonu', 'caus', 'address', 'inform', 'player', 'complet', 'stori', 'nite', 'wid', 'full', 'tot', 'sae', 'famili', 'togeth', 'goin', 'sad', 'forget', 'numberpatpm', 'isnt', 'old', 'match', 'content', 'believ', 'touch', 'noe', 'ring', 'club', 'oki', 'numberpatu', 'reason', 'huh', 'land', 'listen', 'train', 'email', 'murder', 'treat', 'aft', 'fri', 'took', 'privat', 'dog', 'everyon', 'studi', 'grnumberpat', 'awesom', 'break', 'die', 'wil', 'coz', 'unsubscrib', 'eve', 'mum', 'rite', 'anyon', 'caller', 'congrat', 'move', 'download', 'prob', 'statement', 'expir', 'age', 'nonumberpat', 'fanci', 'compani', 'angri', 'park', 'choos', 'card', 'sister', 'valentin', 'current', 'bnumberpat', 'simpl', 'tsc', 'neva', 'pub', 'laugh', 'sell', 'valu', 'news', 'tho', 'tomo', 'seem', 'lucki', 'ta', 'bday', 'bank', 'worth', 'found', 'sort', 'forward', 'mine', 'whatev', 'knw', 'parent', 'alon', 'auction', 'avail', 'joke', 'winner', 'pobox', 'ha', 'smth', 'saturday', 'pass', 'song', 'save', 'oper', 'ticket', 'uncl', 'unredeem', 'identifi', 'type', 'hard', 'log', 'boytoy', 'colleg', 'bill', 'exam', 'secret', 'anytim', 'far', 'fone', 'numberpatpmsg', 'mobileupdnumberpat', 'welcom', 'kind', 'visit', 'outsid', 'sun', 'sit', 'gd', 'parti', 'surpris', 'crazi', 'camcord', 'cut', 'follow', 'youll', 'rain', 'gone', 'hit', 'friday', 'mu', 'nt', 'ltd', 'wit', 'carlo', 'mrng', 'oredi', 'case', 'congratul', 'boxnumberpat', 'light', 'return', 'project', 'bout', 'th', 'cum', 'nope', 'pretti', 'sea', 'fast', 'drug', 'wasnt', 'wkli', 'hungri', 'confirm', 'whole', 'comput', 'ninumberpat', 'spend', 'youv', 'wed', 'cours', 'darlin', 'goodmorn', 'ga', 'meant', 'fix', 'cd', 'unlimit', 'mnumberpat', 'numberpatmth', 'interest', 'jay', 'rock', 'ad', 'ten', 'suppos', 'differ', 'scream', 'remov', 'term', 'cs', 'kid', 'snow', 'opt', 'gal', 'poboxnumberpat', 'understand', 'wrong', 'numberpatday', 'promis', 'turn', 'catch', 'usual', 'almost', 'correct', 'etc', 'hee', 'shower', 'mah', 'felt', 'quiz', 'tire', 'wine', 'joy', 'march', 'side', 'tel', 'fr', 'dnt', 'singl', 'bslvyl', 'lost', 'figur', 'moment', 'st', 'motorola', 'coupl', 'ass', 'pm', 'fight', 'savamob', 'sub', 'within', 'marri', 'yar', 'area', 'paper', 'sex', 'knew', 'least', 'earlier', 'nyt', 'film', 'chennai', 'tht', 'fren', 'w', 'freemsg', 'reward', 'eh', 'nation', 'eg', 'cheer', 'crave', 'hospit', 'wow', 'complimentari', 'xx', 'load', 'askd', 'direct', 'activ', 'phonenumbernumberpat', 'safe', 'hell', 'mr', 'connect', 'semest', 'bcoz', 'laptop', 'blue', 'swing', 'normal', 'christma', 'via', 'ago', 'chikku', 'seen', 'slow', 'rental', 'rent', 'ipod', 'remind', 'gym', 'darren', 'an', 'eye', 'store', 'ugh', 'extra', 'photo', 'truth', 'fill', 'support', 'grin', 'luck', 'difficult', 'john', 'father', 'comp', 'usf', 'request', 'copi', 'link', 'comin', 'abiola', 'stand', 'loan', 'page', 'txting', 'sometim', 'muz', 'deal', 'orchard', 'kate', 'regist', 'teach', 'expect', 'lover', 'disturb', 'wana', 'sim', 'somebodi', 'small', 'discount', 'india', 'doin', 'hmm', 'silent', 'ladi', 'warm', 'clean', 'door', 'noon', 'idea', 'fall', 'whenev', 'numberpatg', 'heard', 'frm', 'cancel', 'fantasi', 'fact', 'slowli', 'hr', 'nah', 'callertun', 'press', 'info', 'wap', 'england', 'sick', 'oop', 'situat', 'forev', 'short', 'recent', 'rpli', 'repres', 'numberpatamnumberpatpm', 'gave', 'men', 'apart', 'quot', 'del', 'lovabl', 'pray', 'wast', 'trust', 'rs', 'sign', 'road', 'kick', 'admir', 'deep', 'hmv', 'stupid', 'somewher', 'pete', 'record', 'immedi', 'access', 'weed', 'met', 'ex', 'woke', 'mm', 'yep', 'voic', 'ldn', 'ure', 'style', 'monday', 'water', 'near', 'opinion', 'less', 'member', 'across', 'cheap', 'em', 'ho', 'gap', 'fantast', 'glad', 'summer', 'gettin', 'reveal', 'poor', 'asap', 'otherwis', 'ntt', 'possibl', 'convey', 'regard', 'doctor', 'who', 'energi', 'nobodi', 'write', 'share', 'natur', 'numberpati', 'excus', 'med', 'empti', 'cup', 'std', 'bless', 'serious', 'mark', 'boss', 'flight', 'app', 'sunshin', 'soni', 'lazi', 'lect', 'becom', 'hmmm', 'lift', 'especi', 'mrt', 'appreci', 'street', 'flirt', 'definit', 'unless', 'teas', 'rose', 'sport', 'accept', 'rest', 'power', 'merri', 'round', 'urself', 'basic', 'bluetooth', 'refer', 'mistak', 'kinda', 'result', 'optout', 'depend', 'meh', 'self', 'hotel', 'hurri', 'indian', 'xy', 'king', 'add', 'subscrib', 'wwwgetzedcouk', 'aint', 'bid', 'chariti', 'tampa', 'user', 'mid', 'sale', 'wear', 'hiya', 'f', 'digit', 'p', 'deliv', 'mode', 'other', 'bb', 'total', 'numberpatnit', 'arriv', 'list', 'thinkin', 'flag', 'colleagu', 'tear', 'entitl', 'anymor', 'sunday', 'pizza', 'clear', 'quick', 'learn', 'roommat', 'letter', 'youd', 'nigeria', 'ice', 'cinema', 'spent', 'pleasur', 'troubl', 'coffe', 'ave', 'inc', 'bother', 'bak', 'dvd', 'goto', 'moneysymb', 'experi', 'where', 'freephon', 'howev', 'settl', 'dead', 'success', 'slept', 'gt', 'file', 'ufind', 'rreveal', 'specialcal', 'uve', 'goodnight', 'tnc', 'lemm', 'celebr', 'wiv', 'hgsuitenumberpatnumberpatland']\n"
     ]
    }
   ],
   "source": [
    "most_common_features = [word for word, _ in features_freq.most_common(1000)]\n",
    "print(\"most common words\", most_common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(message):\n",
    "  words = word_tokenize(message)\n",
    "  features = {}\n",
    "  for word in most_common_features:\n",
    "    features[word] = (word in words)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find features for all messages\n",
    "messages = list(zip(processed_text, Y))\n",
    "np.random.shuffle(messages)\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set for training and testing\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining models\n",
    "names = [\n",
    "  # 'K Nearest Neighbor', KNN too slow and accuracy is very poor, so will not be using\n",
    "  'Decision Tree',\n",
    "  ' Random Forest',\n",
    "  'Logistic Regression',\n",
    "  ' SGD Classifier',\n",
    "  'Naive Bayes',\n",
    "  'SVM Linear'\n",
    "]\n",
    "\n",
    "classifier = [\n",
    "  # KNeighborsClassifier(),\n",
    "  DecisionTreeClassifier(),\n",
    "  RandomForestClassifier(),\n",
    "  LogisticRegression(),\n",
    "  SGDClassifier(max_iter = 100),\n",
    "  MultinomialNB(),\n",
    "  SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbor: Accuracy: 93.96984924623115\n",
      "Decision Tree: Accuracy: 97.70279971284997\n",
      " Random Forest: Accuracy: 98.77961234745155\n",
      "Logistic Regression: Accuracy: 98.85139985642498\n",
      " SGD Classifier: Accuracy: 98.77961234745155\n",
      "Naive Bayes: Accuracy: 98.06173725771716\n",
      "SVM Linear: Accuracy: 98.85139985642498\n"
     ]
    }
   ],
   "source": [
    "# training and testing models\n",
    "for name, model in models:\n",
    "  nltk_model = SklearnClassifier(model)\n",
    "  nltk_model.train(training)\n",
    "  accuracy = nltk.classify.accuracy(nltk_model, testing) * 100\n",
    "  print('{}: Accuracy: {}'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Method Accuracy: 98.99497487437185\n"
     ]
    }
   ],
   "source": [
    "# building ensemble classifier\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, testing) * 100\n",
    "print('Ensemble Method Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_features, labels = list(zip(*testing))\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1209\n",
      "           1       1.00      0.92      0.96       184\n",
      "\n",
      "    accuracy                           0.99      1393\n",
      "   macro avg       0.99      0.96      0.98      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>14</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1209    0\n",
       "       spam        14  170"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "  confusion_matrix(labels, prediction),\n",
    "  index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "  columns = [['predicted', 'predicted'], ['ham', 'spam']] \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
